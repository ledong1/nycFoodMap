{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize \n",
    "import warnings \n",
    "\n",
    "warnings.filterwarnings(action = 'ignore') \n",
    "\n",
    "import gensim \n",
    "from gensim.models import Word2Vec \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.load('nycfoodmap.npy')\n",
    "b=b.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = [line.strip().decode('utf-8') for line in open('cn_stopwords.txt','rb').readlines()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents=[]\n",
    "for each in b:\n",
    "    sents = sents + each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleared_sents=[]\n",
    "for each in sents:\n",
    "    deep=[]\n",
    "    cleaned_data = ''.join(re.findall(r'[\\u4e00-\\u9fa5]', each))\n",
    "    wordlist = jieba.lcut(cleaned_data)\n",
    "    for word in wordlist:\n",
    "        if word not in stop:\n",
    "            deep.append(word)\n",
    "    cleared_sents.append(deep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = gensim.models.Word2Vec(cleared_sents, min_count = 1, size = 300, window = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('纯素', 0.9987005591392517), ('火锅店', 0.9985907673835754), ('新奇', 0.9985045194625854), ('征服', 0.9984232783317566), ('营养', 0.9984208345413208), ('总体', 0.9983618259429932), ('注重', 0.9983446002006531), ('秋冬', 0.9981027841567993), ('没什么', 0.9979938268661499), ('以外', 0.997982382774353)]\n"
     ]
    }
   ],
   "source": [
    "print( model1.wv.most_similar('韩国'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
